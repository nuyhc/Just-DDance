{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype_2\n",
    "### 추출해와서 출력하기\n",
    "\n",
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pytube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JustDDance:\n",
    "    def __init__(self):\n",
    "        self.__download_path = \"../dataset/video/\"\n",
    "        self.__keyporint_extraction_path = \"../dataset/keypoint_extraction/\"\n",
    "        self.__dance_fps = None\n",
    "        self.__dance_shape = None\n",
    "        self.__user_fps = None\n",
    "        self.__user_shape = None\n",
    "        self.__const_k = 0.3\n",
    "    \n",
    "    def download_video(self):\n",
    "        url = input(\"연습할 춤의 유튜브 링크: \")\n",
    "        yt = pytube.YouTube(url)\n",
    "        stream = yt.streams.filter(res=\"720p\").first()\n",
    "        stream.download(self.__download_path)\n",
    "    \n",
    "    def scaling_coor(self, keypoint_path): # \"./keypoint_extraction/[주간아 직캠] IVE YUJIN - LOVE DIVE (아이브 유진 - 러브 다이브) l EP556_keypoints.json\"\n",
    "        with open(keypoint_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        pose_cor = pd.DataFrame(data[\"pose\"])\n",
    "        return np.array(pose_cor)\n",
    "    \n",
    "    def extract_keypoint(self, video_path):\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        mp_drawing_style = mp.solutions.drawing_styles\n",
    "        mp_holistic = mp.solutions.holistic\n",
    "        \n",
    "        keypoint_dict_pose = []\n",
    "        keypoint_dict_left_hand = []\n",
    "        keypoint_dict_right_hand = []\n",
    "        keypoint_dict = {}\n",
    "        \n",
    "        try: cap = cv2.VideoCapture(video_path)\n",
    "        except: return -1\n",
    "        \n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            while cap.isOpened():\n",
    "                success, image = cap.read()\n",
    "                if not success: break\n",
    "                self.__dance_shape = image.shape\n",
    "                self.__dance_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "                results = holistic.process(image)\n",
    "                try:\n",
    "                    keypoint_dict_pose.append({str(idx): [lmk.x, lmk.y, lmk.z] for idx, lmk in enumerate(results.pose_landmarks.landmark)})\n",
    "                    keypoint_dict_left_hand.append({str(idx): [lmk.x, lmk.y, lmk.z] for idx, lmk in enumerate(results.left_hand_landmarks.landmark)})\n",
    "                    keypoint_dict_right_hand.append({str(idx): [lmk.x, lmk.y, lmk.z] for idx, lmk in enumerate(results.right_hand_landmarks.landmark)})\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                keypoint_dict = {\"pose\": keypoint_dict_pose, \"left_hand\": keypoint_dict_left_hand, \"right_hand\": keypoint_dict_right_hand}\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        with open(self.__keyporint_extraction_path+video_path.split(\"/\")[2].split(\".\")[0]+\"_keypoints.json\", \"w\") as fp:\n",
    "            json.dump(keypoint_dict, fp)\n",
    "            \n",
    "    def show_dance_tutorial(self, video_path, keypoint_path):\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        mp_drawing_style = mp.solutions.drawing_styles\n",
    "        mp_holistic = mp.solutions.holistic\n",
    "        \n",
    "        try: cap = cv2.VideoCapture(0)\n",
    "        except: cap = cv2.VideoCapture(1)\n",
    "        load_dance = cv2.VideoCapture(video_path)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        \n",
    "        dance_cors = self.scaling_coor(keypoint_path)\n",
    "        dance_cors_fps = 0\n",
    "        extract_points = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "        cv2.startWindowThread()\n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            while cap.isOpened():\n",
    "                success, image = cap.read()\n",
    "                ret, dance = load_dance.read()\n",
    "                if not success: break\n",
    "                if not ret: break\n",
    "                self.__user_shape = image.shape\n",
    "                self.__user_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                self.__dance_shape = dance.shape\n",
    "                self.__dance_fps = load_dance.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "                image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "                results = holistic.process(image)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                try:\n",
    "                    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=3, circle_radius=1),\n",
    "                                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=3, circle_radius=1))\n",
    "                    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=3, circle_radius=1),\n",
    "                                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=3, circle_radius=1))\n",
    "                    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=3, circle_radius=1),\n",
    "                                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=3, circle_radius=1))\n",
    "                    skeleton = {}\n",
    "                    # for pose_point in range(33):\n",
    "                    for pose_point in extract_points:\n",
    "                        scale_x_cor_pose, scale_y_cor_pose = int(dance_cors[dance_cors_fps][pose_point][0]*self.__user_shape[1]), int(dance_cors[dance_cors_fps][pose_point][1]*self.__user_shape[0])\n",
    "                        cv2.circle(image, (scale_x_cor_pose, scale_y_cor_pose), 5, (224, 224, 224), cv2.FILLED)\n",
    "                        skeleton[pose_point] = (scale_x_cor_pose, scale_y_cor_pose)\n",
    "                        # Acc (L2 Norm)\n",
    "                        tn_x, tn_y, tn_z = dance_cors[dance_cors_fps][pose_point][0:3]\n",
    "                        user_input = [[lmk.x, lmk.y, lmk.z] for lmk in results.pose_landmarks.landmark]\n",
    "                        user_x, user_y, user_z = user_input[pose_point][0:3]\n",
    "                        acc = np.round(self.__const_k / (np.linalg.norm([tn_x-user_x, tn_y-user_y, tn_z-user_z]) + self.__const_k), 2)*100\n",
    "                    dance_cors_fps += 1\n",
    "                    cv2.putText(image, str(acc)+\"%\", (20, 50), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=(0, 0, 255), thickness=1, lineType=cv2.LINE_AA)\n",
    "                    # 오른쪽 스켈레톤 (붉은색)\n",
    "                    cv2.line(image, skeleton[12], skeleton[14], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/어깨 -> 오/팔꿈치\n",
    "                    cv2.line(image, skeleton[14], skeleton[16], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/팔꿈치 -> 오/손목\n",
    "                    cv2.line(image, skeleton[12], skeleton[24], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/어깨 -> 오/엉덩이\n",
    "                    cv2.line(image, skeleton[24], skeleton[26], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/엉덩이 -> 오/무릎\n",
    "                    cv2.line(image, skeleton[26], skeleton[28], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/무릎 -> 오/발목\n",
    "                    cv2.line(image, skeleton[28], skeleton[30], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/발목 -> 오/뒷꿈치\n",
    "                    cv2.line(image, skeleton[30], skeleton[32], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오른발\n",
    "                    cv2.line(image, skeleton[28], skeleton[32], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오른발\n",
    "                    # 왼쪽 스켈레톤 (푸른색)\n",
    "                    cv2.line(image, skeleton[11], skeleton[13], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/어깨 -> 왼/팔꿈치\n",
    "                    cv2.line(image, skeleton[13], skeleton[15], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/팔꿈치 -> 왼/손목\n",
    "                    cv2.line(image, skeleton[11], skeleton[23], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/어깨 -> 왼/엉덩이\n",
    "                    cv2.line(image, skeleton[23], skeleton[25], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/엉덩이 -> 왼/무릎\n",
    "                    cv2.line(image, skeleton[25], skeleton[27], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/무릎 -> 왼/발목\n",
    "                    cv2.line(image, skeleton[27], skeleton[29], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/발목 -> 왼/뒷꿈치\n",
    "                    cv2.line(image, skeleton[29], skeleton[31], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼발\n",
    "                    cv2.line(image, skeleton[27], skeleton[31], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼발\n",
    "                    \n",
    "                    cv2.line(image, skeleton[11], skeleton[12], (224, 224, 224), thickness=5, lineType=cv2.LINE_AA, shift=None)\n",
    "                    cv2.line(image, skeleton[23], skeleton[24], (224, 224, 224), thickness=5, lineType=cv2.LINE_AA, shift=None)\n",
    "                except:\n",
    "                    pass\n",
    "                # TODO: 싱크 문제 해결\n",
    "                h_output = np.hstack((cv2.flip(dance, 1), image))\n",
    "                cv2.imshow(\"Just DDance!\", h_output)\n",
    "                if cv2.waitKey(1)&0xFF==ord(\"q\"): break\n",
    "        load_dance.release()        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = JustDDance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jd.extract_keypoint(\"../dataset/video/IVE_YUJIN_-_LOVE_DIVE__-__l_EP556.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd.show_dance_tutorial(\"../dataset/video/IVE_YUJIN_-_LOVE_DIVE__-__l_EP556.mp4\",\"../dataset/keypoint_extraction/video_keypoints.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25cc1cd7561f80357b7fa03267e13bd0c2330c203ad8a304d4fde6c3e39963dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
