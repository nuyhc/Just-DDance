{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JustDDance():\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_style = mp.solutions.drawing_styles\n",
    "    mp_pose = mp.solutions.pose\n",
    "    def __init__(self, const_k=0.3):\n",
    "        self.__const_k = const_k\n",
    "        self.__video_download_path = \"video\"\n",
    "        self.__keypoints_path = \"keypoints\"\n",
    "        self.__dance_name = None\n",
    "        self.__accumulate_acc = []\n",
    "    def set_const_k(self):\n",
    "        self.__const_k = float(input(\"난이도 조절(0~1 사이 값): \"))\n",
    "    def get_const_k(self):\n",
    "        print(f\"현재 난이도: {self.__const_k}\")\n",
    "    def __get_accumlate_acc(self):\n",
    "        return self.__accumulate_acc\n",
    "    def __save_dance_name(self):\n",
    "        self.__dance_name = input(\"누구의 무슨 춤?: 안유진 러브다이브\")\n",
    "    def set_dance_name(self, s):\n",
    "        self.__dance_name = s\n",
    "    def print_dance_data(self):\n",
    "        acc_acc = self.__get_accumlate_acc()\n",
    "        accMax, accMin, accMean = np.max(acc_acc), np.min(acc_acc), np.mean(acc_acc)\n",
    "        print(f\"Max Acc: {accMax}\\nMin Acc: {accMin}\\nAvg. Acc: {accMean}\")\n",
    "        acc_acc = pd.DataFrame(acc_acc)\n",
    "        acc_acc.plot(figsize=(25, 6))\n",
    "        plt.title(\"Acc for Frames\")\n",
    "        plt.xlabel(\"Frames\")\n",
    "        plt.ylabel(\"Accuarcy\")\n",
    "        plt.legend(\"Accuarcy\")\n",
    "        plt.axhline(y=70, color=\"r\")\n",
    "        plt.show()\n",
    "    def download_video(self):\n",
    "        self.__save_dance_name()\n",
    "        url = input(f\"{self.__dance_name}의 안무 영상 링크: \")\n",
    "        if not os.path.exists(self.__video_download_path): os.mkdir(self.__video_download_path)\n",
    "        yt = pytube.YouTube(url).streams.filter(res=\"720p\").first()\n",
    "        yt.download(output_path=self.__video_download_path, filename=self.__dance_name+\".mp4\")\n",
    "    def draw_skeleton(self, image, skeleton):\n",
    "        # 오른쪽 스켈레톤 (붉은색)\n",
    "        cv2.line(image, skeleton[12], skeleton[14], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/어깨 -> 오/팔꿈치\n",
    "        cv2.line(image, skeleton[14], skeleton[16], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/팔꿈치 -> 오/손목\n",
    "        cv2.line(image, skeleton[12], skeleton[24], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/어깨 -> 오/엉덩이\n",
    "        cv2.line(image, skeleton[24], skeleton[26], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/엉덩이 -> 오/무릎\n",
    "        cv2.line(image, skeleton[26], skeleton[28], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/무릎 -> 오/발목\n",
    "        cv2.line(image, skeleton[28], skeleton[30], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오/발목 -> 오/뒷꿈치\n",
    "        cv2.line(image, skeleton[30], skeleton[32], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오른발\n",
    "        cv2.line(image, skeleton[28], skeleton[32], (102, 102, 255), thickness=5, lineType=cv2.LINE_AA, shift=None) # 오른발\n",
    "        # 왼쪽 스켈레톤 (푸른색)\n",
    "        cv2.line(image, skeleton[11], skeleton[13], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/어깨 -> 왼/팔꿈치\n",
    "        cv2.line(image, skeleton[13], skeleton[15], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/팔꿈치 -> 왼/손목\n",
    "        cv2.line(image, skeleton[11], skeleton[23], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/어깨 -> 왼/엉덩이\n",
    "        cv2.line(image, skeleton[23], skeleton[25], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/엉덩이 -> 왼/무릎\n",
    "        cv2.line(image, skeleton[25], skeleton[27], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/무릎 -> 왼/발목\n",
    "        cv2.line(image, skeleton[27], skeleton[29], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼/발목 -> 왼/뒷꿈치\n",
    "        cv2.line(image, skeleton[29], skeleton[31], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼발\n",
    "        cv2.line(image, skeleton[27], skeleton[31], (255, 102, 102), thickness=5, lineType=cv2.LINE_AA, shift=None) # 왼발\n",
    "        # 상체 스켈레톤 (회색)\n",
    "        cv2.line(image, skeleton[11], skeleton[12], (224, 224, 224), thickness=5, lineType=cv2.LINE_AA, shift=None)\n",
    "        cv2.line(image, skeleton[23], skeleton[24], (224, 224, 224), thickness=5, lineType=cv2.LINE_AA, shift=None)   \n",
    "    def __get_margin(self, user_tri, dance_tri):\n",
    "        margin = []\n",
    "        ut = [(user_tri[0][0]+user_tri[1][0]+user_tri[2][0])/3, (user_tri[0][1]+user_tri[1][1]+user_tri[2][1])/3, (user_tri[0][2]+user_tri[1][2]+user_tri[2][2])/3]\n",
    "        dt = [(dance_tri[0][0]+dance_tri[1][0]+dance_tri[2][0])/3, (dance_tri[0][1]+dance_tri[1][1]+dance_tri[2][1])/3, (dance_tri[0][2]+dance_tri[1][2]+dance_tri[2][2])/3]\n",
    "        for u, d in zip(ut, dt): margin.append(u-d)\n",
    "        return margin\n",
    "    def __get_distance(self, pt1, pt2):\n",
    "        return ((pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2)**0.5\n",
    "    def __load_cor_data(self):\n",
    "        with open(self.__keypoints_path+\"/\"+self.__dance_name+\"_keypoints.json\", \"r\") as keypoints:\n",
    "            data = json.load(keypoints)\n",
    "            return np.array(pd.DataFrame(data))\n",
    "    def extract_keypoints(self, isMirr=False, showExtract=False):\n",
    "        if not os.path.exists(self.__keypoints_path): os.mkdir(self.__keypoints_path)\n",
    "        \n",
    "        keypoint_dict_pose = []\n",
    "        \n",
    "        cv2.startWindowThread()\n",
    "        cap = cv2.VideoCapture(os.path.join(self.__video_download_path, self.__dance_name+\".mp4\"))\n",
    "        with self.mp_pose.Pose(model_complexity=2, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "            while cap.isOpened():\n",
    "                ret, image = cap.read()\n",
    "                if not ret: break\n",
    "                if not isMirr: image = cv2.flip(image, 1)\n",
    "                \n",
    "                results = pose.process(image)\n",
    "                # Extracting\n",
    "                try: keypoint_dict_pose.append({str(idx): [lmk.x, lmk.y, lmk.z] for idx, lmk in enumerate(results.pose_landmarks.landmark)})\n",
    "                except: pass\n",
    "                if showExtract:\n",
    "                    self.mp_drawing.draw_landmarks(image, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,\n",
    "                                    landmark_drawing_spec=self.mp_drawing.DrawingSpec(color=(244, 244, 244), thickness=2, circle_radius=1),\n",
    "                                    connection_drawing_spec=self.mp_drawing.DrawingSpec(color=(153, 255, 153), thickness=2, circle_radius=1))\n",
    "                    cv2.imshow(\"Extracting\", image)\n",
    "                    if cv2.waitKey(1)==ord(\"q\"): break\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.waitKey(1)\n",
    "        # Save coord. Data for json type\n",
    "        with open(self.__keypoints_path+\"/\"+self.__dance_name+\"_keypoints.json\", \"w\") as keypoints:\n",
    "            json.dump(keypoint_dict_pose, keypoints)\n",
    "    def show_dance_tutorial(self):\n",
    "        cv2.startWindowThread()\n",
    "        dance = cv2.VideoCapture(os.path.join(self.__video_download_path, self.__dance_name+\".mp4\"))\n",
    "        try: user = cv2.VideoCapture(0)\n",
    "        except: user = cv2.VideoCapture(1)\n",
    "        user.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        user.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        \n",
    "        dance_cors = self.__load_cor_data()\n",
    "        dance_cors_frames = 0\n",
    "        skeletons = {}\n",
    "        pTime = 0\n",
    "        FPS = dance.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        with self.mp_pose.Pose(model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "            while user.isOpened():\n",
    "                cTime = time.time()-pTime\n",
    "                user_ret, user_image = user.read()\n",
    "                dance_ret, dance_image = dance.read()\n",
    "                if not user_ret: break\n",
    "                if not dance_ret: break\n",
    "                \n",
    "                if cTime>1./FPS:\n",
    "                    pTime = time.time()\n",
    "                    acc_per_frame = []\n",
    "                    user_image = cv2.cvtColor(cv2.flip(user_image, 1), cv2.COLOR_BGR2RGB)\n",
    "                    user_results = pose.process(user_image)\n",
    "                    user_image = cv2.cvtColor(user_image, cv2.COLOR_RGB2BGR)\n",
    "                    # 사용자\n",
    "                    self.mp_drawing.draw_landmarks(user_image, user_results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,\n",
    "                                                landmark_drawing_spec = self.mp_drawing.DrawingSpec(color=(244, 244, 244), thickness=2, circle_radius=1),\n",
    "                                                connection_drawing_spec = self.mp_drawing.DrawingSpec(color=(153, 255, 153), thickness=2, circle_radius=1))\n",
    "                    try:\n",
    "                        user_input = {str(idx): [lmk.x, lmk.y, lmk.z] for idx, lmk in enumerate(user_results.pose_landmarks.landmark)}\n",
    "                    except: pass\n",
    "                    # 추출해 온 데이터\n",
    "                    try:\n",
    "                        # get coors MARGIN\n",
    "                        cors_margin = self.__get_margin([user_input[\"0\"], user_input[\"11\"], user_input[\"12\"]], [dance_cors[dance_cors_frames][0], dance_cors[dance_cors_frames][11], dance_cors[dance_cors_frames][12]])\n",
    "                        user_ratio = self.__get_distance(user_input[\"11\"], user_input[\"12\"])\n",
    "                        dance_ratio = self.__get_distance(dance_cors[dance_cors_frames][11], dance_cors[dance_cors_frames][12])\n",
    "                        length_scale = (user_ratio/dance_ratio)\n",
    "                        for pose_point in [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]:\n",
    "                            # x_cor_pose, y_cor_pose, z_cor_pose = int((dance_cors[dance_cors_frames][pose_point][0])*user_image.shape[1]*(1-length_scale)+cors_margin[0]), int((dance_cors[dance_cors_frames][pose_point][1])*user_image.shape[0]*(1-length_scale)+cors_margin[1]), int((dance_cors[dance_cors_frames][pose_point][2]+cors_margin[2])*1000)\n",
    "                            x_cor_pose, y_cor_pose, z_cor_pose = int((dance_cors[dance_cors_frames][pose_point][0]+cors_margin[0])*user_image.shape[1]), int((dance_cors[dance_cors_frames][pose_point][1]+cors_margin[1])*user_image.shape[0]), (dance_cors[dance_cors_frames][pose_point][2]) # Tracking\n",
    "                            cv2.circle(user_image, (x_cor_pose, y_cor_pose), 5, (244, 244, 244), cv2.FILLED)\n",
    "                            skeletons[pose_point] = (x_cor_pose, y_cor_pose)\n",
    "                            # print(x_cor_pose, y_cor_pose, user_input[str(pose_point)][0], user_input[str(pose_point)][1])\n",
    "                            # L2 Norm\n",
    "                            acc_per_frame.append(np.round(self.__const_k / (np.linalg.norm([x_cor_pose/user_image.shape[1]-user_input[str(pose_point)][0], y_cor_pose/user_image.shape[0]-user_input[str(pose_point)][1], z_cor_pose-user_input[str(pose_point)][2]]) + self.__const_k), 2))\n",
    "                            acc = np.mean(acc_per_frame)*100\n",
    "                            self.__accumulate_acc.append(acc)\n",
    "                        cv2.putText(user_image, str(acc)+\"%\", (20, 50), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=(0, 0, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "                        self.draw_skeleton(user_image, skeletons)\n",
    "                        dance_cors_frames +=1\n",
    "                    except: pass\n",
    "                    \n",
    "                    h_output = np.hstack((cv2.flip(dance_image, 1), user_image))\n",
    "                    cv2.imshow(\"Just DDance!\", h_output)\n",
    "                if cv2.waitKey(1)&0xFF==ord(\"q\"): break\n",
    "        user.release()\n",
    "        dance.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yoloV5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1581ea2858f85162264ff98844704fe519c05d353e8b65c223f8582cc62ba8b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
